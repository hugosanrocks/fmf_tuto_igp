%=== Préambule ===========================================================

\documentclass[aspectratio=169]{beamer}
\usepackage[english]{babel}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{pdfpages}
\usepackage{tikz}
\usepackage{natbib}

\usepackage{color}
\input{images/rgb}


\uselanguage{English}
\languagepath{English}
\setcounter{tocdepth}{1}

\lstset{
  numbers=left,
  basicstyle=\tiny\ttfamily,      
  breaklines=true, 
  showtabs=false,
  showstringspaces=false,
}  

%=== Configuration de Beamer et du thème metropolis ======================

\usetheme[background=light]{metropolis}

\definecolor{mLightBrown}{HTML}{000000}
\definecolor{black}{HTML}{000000}
\setbeamercolor{structure}{fg=black,bg=mLightBrown}
\setbeamercolor{palette primary}{%
	use=normal text,
	fg=normal text.bg,
	bg=mLightBrown
}
%\setsansfont[BoldFont={Linux Libertine G Bold},Numbers={OldStyle}]{Linux Libertine G}

\metroset{block=fill}

%=== Page de titre =======================================================

%path to logo and biblio -> to be adapted to your local directories 
\newcommand\dirlogo{~/Public/hugosanrocks.github.com/tex_documents/logos/}
\newcommand\dirbiblio{../../biblio/,/}



\title{{\vskip 1.5cm Curso 1: Teor\'ia de inversi\'on y programaci\'on en Python}}
\subtitle{}
\author{H. S\'anchez-Reyes}

\institute[ISTerre, Universit\'e de Grenoble Alpes]
{
ISTerre, Universit\'e de Grenoble Alpes, France\\
\textit{IRD - UGA-ISTerre BQR Project} \vskip 1cm
7-18 de Agosto de 2023\\
Lima, Per\'u
}

\date[2023]{}%2020 AGU Fall Meeting, 8th December}
\subject{}

\titlegraphic{\centering \vspace{-15pt}\includegraphics[height=1.2cm]{\dirlogo/IRD.png} \qquad \quad \includegraphics[height=1.2cm]{\dirlogo/UGA} \qquad \quad \includegraphics[height=1.2cm]{\dirlogo/ISTerre} \par \vskip 3cm \hskip 8cm \includegraphics[height=2cm]{\dirlogo/IGP.jpeg}\\ \hskip 8cm ¡Gracias por la bienvenida!}


\addtobeamertemplate{frametitle}{}{%
\begin{tikzpicture}[remember picture,overlay]
  \node[anchor=north east,yshift=0.0ex] at (current page.north east) {\includegraphics[height=4ex]{\dirlogo/IRD_inv.png}};
  %\node[anchor=north east,yshift=0.5ex] at (current page.north east) {\includegraphics[height=3.3ex]{\dirlogo/seiscope_color_light_background}};
\end{tikzpicture}}



%=== Document ============================================================

\begin{document}

% --- Préambule ---------------------------------------------------------------

\begin{frame}
    \titlepage
\end{frame}

\section{\small Recordando algebra lineal}

\begin{frame}
 {Vectores, matrices, elementos y operaciones b\'asicas}

 {\color{black}
 \vskip -0.1cm
 Vectores: 
 \begin{equation*}
  v = [2, 4, 5] \qquad  \textnormal{or,} \qquad n = 
  \begin{bmatrix}
  1 \\ 5 \\ 7    
  \end{bmatrix}
 \end{equation*}
\pause
 \vskip -0.4cm
¿Cu\'al es la dimensi\'on de estos vectores? \pause
 \vskip -0.4cm
 \begin{equation*}
  v = [2, 4, 5]_{1\times3} \qquad  \textnormal{or,} \qquad n = 
  \begin{bmatrix}
  1 \\ 5 \\ 7    
  \end{bmatrix}_{3\times1}
 \end{equation*}
 \pause
 \vskip -0.4cm
 Tambi\'en definimos los transpuestos:
 \vskip -0.4cm
 \pause
 \begin{equation*}
  v^T =
  \begin{bmatrix}
   2 \\ 4 \\ 5
  \end{bmatrix}_{3\times1} \qquad  \textnormal{or,} \qquad n^T = 
  [1, 5, 7]_{1\times3}
 \end{equation*}
}

\end{frame}


\begin{frame}
 {Vectores, matrices, elementos y operaciones b\'asicas}

{ \color{black}
Matrix:
\begin{equation*}
  \begin{bmatrix}
   4 & 1 & 0 \\
   2 & 7 & 2 \\
   5 & 3 & 8 
  \end{bmatrix}_{3\times3}
 \end{equation*}
 \pause
Matrices con definiciones importantes 
\vskip -0.2cm
 \begin{equation*}
 \textnormal{Identidad:} \pause \quad I = \begin{bmatrix}
   1 & 0 & 0 \\
   0 & 1 & 0 \\
   0 & 0 & 1 
  \end{bmatrix}, \textnormal{es decir}, I_{ij} = 1, \textnormal{si \,} i = j, \textnormal{sino \,} I_{ij} = 0 \pause 
 \end{equation*} \pause
 \begin{equation*}
     \textnormal{Sim\'etricas:} \pause \quad \textnormal{siendo $X$ una matríz}\quad X = \begin{bmatrix}
   x_{11} & x_{12} & x_{13} \\
   x_{21} & x_{22} & x_{23} \\
   x_{31} & x_{32} & x_{33} 
  \end{bmatrix} 
 \end{equation*}
 $X$ es simétrica sí, $x_{ij} = x_{ji}$
}

\end{frame}


\begin{frame}
 {Vectores, matrices, elementos y operaciones b\'asicas}

{ \color{black}
 Invertible: \pause \quad si, \quad $\det(M) \neq 0$ \quad entonces, \quad $M^{-1}$ (la inversa de $M$) existe, tal que 
 \begin{equation*}
  M^{-1}M = I = MM^{-1}
 \end{equation*}
 \pause \vskip -1.4cm
 \begin{equation*}
  \underbrace{M^{-1}}_{pre-multiplicar}M = I = M\underbrace{M^{-1}}_{post-multiplicar}
 \end{equation*}
}
 
\end{frame}



\begin{frame}
 {Vectores, matrices, elementos y operaciones b\'asicas}

{\color{black}
 \vskip 0cm
 Sumas (y restas): 
 \begin{center}  
 \vskip -1cm
 \includegraphics[width=0.5\linewidth]{images/sum_matrix.png} \\ \pause
 es decir, $S_{ij} = M_{ij} + N_{ij}$ \quad y \quad $D_{ij} = M_{ij} - N_{ij}$
 \end{center}
 \pause
\vskip -0.3cm Multiplicaciones: \pause
 \begin{center}
 \vskip -0.4cm \includegraphics[width=0.9\linewidth]{images/multiplication.png} \\ \pause
 \vskip -1.2cm es decir,
 \vskip -0.8cm \begin{equation*}
  P_{ij} = \sum^{K}_{k=1} M_{ik}N_{kj}
 \end{equation*}
 \end{center}
}

\end{frame}

\begin{frame}
 {Vectores, matrices, elementos y operaciones b\'asicas}
 
 {\color{black}
 Determinante de una matríz $M$: \pause
 \begin{equation*}
  \det{(M)} = \sum^N_{i=1}  \sum^N_{j=1}  \sum^N_{k=1} \dots \sum^N_{q=1} e^{ijk\dots q} M_{1i} M_{2j} M_{3k} \dots M_{Nq}
 \end{equation*} 
siendo $e^{ijk\dots q} +1$ cuando (i, j, k, ... , q) son permutations pares de (1, 2, 3, ... , N), y $-1$ cuando son permutaciones impares, y cero en otro caso.
 \pause
 \begin{equation*}
  \det{\begin{bmatrix}
        a & b \\
        c & d 
       \end{bmatrix}} = ad - bc
 \end{equation*}
}

\end{frame}

\begin{frame}
 {Vectores, matrices, elementos y operaciones b\'asicas}
 
\vskip -0.2cm
{\color{black}
Y la matriz adjunta de la matriz A es:
\vskip -0.2cm
La matriz adjunta es aquella en la que cada elemento $a_{ij}$ de la matriz $A$ se sustituye por su adjunto. Se llama adjunto del elemento $a_{ij}$ al menor complementario anteponiendo:
\vskip -0.2cm
\begin{itemize}
 \item {\color{black} El signo es + si i+j es par.}
 \item {\color{black} El signo es - si i+j es impar.}
\end{itemize} 
\vskip -0.2cm
¿Cuál es la matriz adjunta de $A$? Siendo A:
\vskip -0.4cm
\begin{equation*}
 \begin{bmatrix}
  a_{11} & a_{12} \\
  a_{21} & a_{22}
 \end{bmatrix}
\end{equation*}
\pause
\vskip -0.4cm
El primer elemento de adj($A$) se encuentra sustituyendo a $a_{11}$ por su menor complementario:

\begin{center}
\vskip -0.6cm \includegraphics[width=0.6\linewidth]{images/adjunta.png} 
\end{center}
}

\end{frame}



\begin{frame}
 
  suponiendo que:
 \vskip -0.5cm
 \begin{equation*}
  A = \begin{bmatrix}
       a & b \\
       c & d
      \end{bmatrix}
 \end{equation*}

¿Cuál es la matríz $A^{-1}$? (tienen 5 min):

\pause
\pause
\begin{equation*}
 \mathbf{A}^{-1} = \frac{1}{\text{det}(\mathbf{A})} \begin{bmatrix}
d & -b \\
-c & a \\
\end{bmatrix}
\end{equation*}

 
\end{frame}



\begin{frame}
 {Linealidad de un sistema}
 
 \pause
 Para demostrar que un sistema es lineal, se deben cumplir las siguientes propiedades:

 Aditividad: \pause Para cualquier par de matrices {\bf A} y {\bf B} y cualquier escalar $\alpha$

\begin{align*}
f(\mathbf{A} + \mathbf{B}) &= f(\mathbf{A}) + f(\mathbf{B}) \\
f(\alpha \mathbf{A}) &= \alpha f(\mathbf{A})
\end{align*}
 
Homogeneidad: \pause

\begin{align*}
f(\alpha \mathbf{A} + \beta \mathbf{A}) &= \alpha f(\mathbf{A}) + \beta f(\mathbf{A})
\end{align*}

\end{frame}


\begin{frame}
 {Vectores, matrices, elementos y operaciones b\'asicas}

 \begin{center}
  \Large M\'as in \cite{Menke_2018_GEO}
 \end{center}
 
\end{frame}




\section{\small I. Problema directo / Forward problem}

\section{\small II. Problema inverso / Inverse problem}

\section{\small III. Problema lineal / Linear problem}

\section{\small IV. Problema no-lineal / Non-linear problem}

\begin{frame}
 
{\color{black}Podemos encuentrar $m^{est}$ que minimice $L=m^Tm=\sum{m_i}^2$, sujeto a la condición límite de mínimo error $e = d - Gm = 0$. Este problema se puede fácilmente resolver con el método de los multiplicadores de Lagrange. Sólo se requiere minimar la función:
 \begin{equation}
  \phi(m) = L + \sum_{i=1}^N{\lambda_i e_i} = \sum_{i=1}^M m^2_i + \sum_{i=1}^N{ \lambda_i   \left[ d_i - \sum^M_{j=1} G_{ij}m_j\right]
}
\end{equation}


Para solucionar este problema de minimización, derivamos la ecuación e igualamos a cero,

\begin{equation}
 \frac{\partial\phi}{\partial m_q} = 
 \sum_{i=1}^M 2 \frac{\partial m_i}{\partial m_q} m_i - \sum_{i=1}^N \lambda_i 
 \sum_{j=1}^M {G_{ij} \frac{\partial m_j}{\partial m_q}} = 2m_q - \sum_{i=1}^N{\lambda_i G_{iq}}
\end{equation}

e igualando a cero,

\begin{equation}
 2m =  G^T \lambda
\end{equation}
}
 
\end{frame}

\begin{frame}
 
{\color{black} Dicha ecuación, $2m=G^T\lambda$, debe ser resulta junto con la ecuación que conocemos $Gm = d$. Sustituyendo la primera ecuación en la segunda, obtenemos que 

\begin{equation}
 m^{est} = G^T (GG^T)^{-1} d
\end{equation}
}
 
\end{frame}

\begin{frame}

{\color{black}
Idealmente, otra posibilidad sería que nos gustaría clasificar los parámetros del modelo desconocidos en dos grupos: aquellos que están sobredeterminados y aquellos que están indeterminados. Para lograr esto, necesitamos formar un nuevo conjunto de parámetros del modelo que sean combinaciones lineales de los anteriores. 

Por ejemplo, querríamos realizar esta partición a partir de una ecuación arbitraria $Gm = d \quad \rightarrow  G'm'= d'$, donde $m'$ se divide en una parte superior $m'^o$ que está sobredeterminada y una parte inferior $m'^u$ que está indeterminada:

\begin{equation}
 \begin{bmatrix}
 G'^o & 0 \\
 0    & G'^u 
 \end{bmatrix} 
 \begin{bmatrix}
  m'^o \\
  m'^u 
 \end{bmatrix} = 
 \begin{bmatrix}
  d'^o \\
  d'^u
 \end{bmatrix}
\end{equation}
}

\end{frame}


\begin{frame}

{\color{black}
 En lugar de dividir $m$ en partes, supongamos que determinamos una solución que minimiza alguna combinación $\phi$ del error de predicción y la longitud de la solución para los parámetros del modelo no divididos:
 
 \begin{equation}
  \phi(m) = E + \epsilon^2 L = e^Te + \epsilon^2 m^Tm
 \end{equation}
donde el factor de ponderación $\epsilon^2$ determina la importancia relativa que se le da al error de predicción y la longitud de la solución. Si $\epsilon$ se hace lo suficientemente grande, este procedimiento claramente minimizará la parte indeterminada de la solución. Desafortunadamente, también tiende a minimizar la parte sobredeterminada de la solución. Como resultado, la solución no minimizará el error de predicción y no se obtendrá una muy buena estimación de los verdaderos parámetros del modelo que se busca. Si $\epsilon$ es igual a cero, se minimizará el error de predicción, pero no se proporcionará información previa para distinguir los parámetros del modelo indeterminados. 
}

\end{frame}


\begin{frame}

{\color{black}
 Sin embargo, puede ser posible encontrar algún valor de compromiso para $\epsilon$ que minimice aproximadamente $E$ y al mismo tiempo minimice aproximadamente la longitud de la parte indeterminada de la solución. No existe un método simple para determinar qué valor de $\epsilon$ debe ser (sin resolver el problema dividido); este debe ser determinado mediante prueba y error. Al minimizar $\phi(m)$ con respecto a los parámetros del modelo de una manera exactamente análoga a la derivación de mínimos cuadrados, obtenemos:

\begin{equation}
 [G^TG + \epsilon^2 I] m^{est} = G^T d
\end{equation}

lo cuál nos lleva a que

\begin{equation}
 m^{est} = [G^TG + \epsilon^2 I]^{-1} G^T d.
\end{equation}
}
 
\end{frame}


\begin{frame}
 {Normas de medición del ajuste}
 
 {
 \color{black}
 Norma L$_1$:
 \begin{equation*}
  ||\textnormal{\bf e}||_1 = \left[ \sum_i |e_i|^1 \right]
 \end{equation*}

 Norma L$_2$:
 \begin{equation*}
  ||\textnormal{\bf e}||_2 = \left[ \sum_i |e_i|^2 \right] ^{\frac{1}{2}}
 \end{equation*}
 
 Norma L$_n$:
 \begin{equation*}
  ||\textnormal{\bf e}||_n = \left[ \sum_i |e_i|^n \right] ^{\frac{1}{n}}
 \end{equation*}
}
 
\end{frame}


\begin{frame}

    \bibliography{biblio}
    \bibliographystyle{apalike}    

\end{frame}


\end{document}

